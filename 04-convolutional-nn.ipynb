{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Final, Literal\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as nnf\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"../cifar_data\")\n",
    "\n",
    "class_names: list[str] = [\n",
    "    'airplane','automobile','bird','cat','deer',\n",
    "    'dog','frog','horse','ship','truck'\n",
    "]\n",
    "\n",
    "# Transform statistics taken from https://stackoverflow.com/a/69750247\n",
    "cifar10_preprocessor = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=cifar10_preprocessor\n",
    ")\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=cifar10_preprocessor\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since I got the normalization values from the Internet, I should verify that these statistics are accurate. I will create numpy batch arrays and take the mean and std along the batch and 32x32 pixel axes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# use np.concatenate to stick all the images together to form a (batch, 3, 32, 32) array\n",
    "imgs = np.concatenate(\n",
    "    np.asarray([[\n",
    "        [\n",
    "            cifar10_train[i][0][0].numpy(),\n",
    "            cifar10_train[i][0][1].numpy(),\n",
    "            cifar10_train[i][0][2].numpy()\n",
    "        ]\n",
    "        for i in range(len(cifar10_train))\n",
    "    ]])\n",
    ")\n",
    "\n",
    "print(imgs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00040607 -0.0005815  -0.00102856]\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean along the (batch, pixel, pixel) axes\n",
    "train_mean = np.mean(imgs, axis=(0, 2, 3))\n",
    "print(train_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0001289  0.9999368  0.99995327]\n"
     ]
    }
   ],
   "source": [
    "# calculate the std along the (batch, pixel, pixel) axes\n",
    "train_std = np.std(imgs, axis=(0, 2, 3))\n",
    "print(train_std)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! The data is normalized with zero mean and standard deviation of one (1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "label_map: dict[int, int] = {0: 0, 2: 1}\n",
    "\n",
    "cifar2_class_names: list[str] = ['airplane', 'bird']\n",
    "cifar10_to_2_indices: list[int] = [\n",
    "    class_names.index(cifar2) for cifar2 in cifar2_class_names\n",
    "]\n",
    "\n",
    "cifar2 = [\n",
    "    (img, label_map[label])\n",
    "    for img, label in cifar10_train\n",
    "    if label in cifar10_to_2_indices\n",
    "]\n",
    "\n",
    "cifar2_val = [\n",
    "    (img, label_map[label])\n",
    "    for img, label in cifar10_val\n",
    "    if label in cifar10_to_2_indices\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device: Final = (\n",
    "    torch.device('cuda') if torch.cuda.is_available()\n",
    "    else torch.device('cpu')\n",
    ")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    \"\"\"Run training on a CNN\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_epochs : int\n",
    "        Number of training iterations\n",
    "    optimizer : optim.Optimizer\n",
    "        Optimizer\n",
    "    model : nn.Module\n",
    "        CNN model\n",
    "    loss_fn : nn.Module\n",
    "        Loss function module\n",
    "    train_loader : DataLoader\n",
    "        Batched data loader\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs_t, labels_t in train_loader:\n",
    "            imgs_t = imgs_t.to(device=device)\n",
    "            labels_t = labels_t.to(device=device)\n",
    "            outputs = model(imgs_t)\n",
    "            loss = loss_fn(outputs, labels_t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch < 4 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    \"\"\"Validate model training\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        Trained model module\n",
    "    train_loader : DataLoader\n",
    "        Training data loading\n",
    "    val_loader : DataLoader\n",
    "        Validation data loader\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, float]\n",
    "        Accuracy dictionary for data loaders. The keys are [\"train\", \"val\"]\n",
    "    \"\"\"\n",
    "    accdict: dict[Literal[\"train\", \"val\"], float] = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs_t, labels_t in loader:\n",
    "                outputs = model(imgs_t)\n",
    "                _, predicted_t = torch.max(outputs, dim=1)\n",
    "                total += labels_t.shape[0]\n",
    "                correct_t = predicted_t == labels_t\n",
    "                correct += int(correct_t.sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-24 10:43:18.876998 Epoch 1, Training loss 0.5529749898394202\n",
      "2022-12-24 10:43:30.517862 Epoch 2, Training loss 0.47473541300767547\n",
      "2022-12-24 10:43:41.394309 Epoch 3, Training loss 0.4375302218327856\n",
      "Accuracy train: 0.82\n",
      "Accuracy val: 0.82\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.8172, 'val': 0.823}"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Cifar2CNN(nn.Module):\n",
    "    \"\"\"CNN image classifier for two (2) classes\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_chans1=32\n",
    "    ):\n",
    "        \"\"\"Instantiate a CNN CIFAR image classifier for two (2) classes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_chans1 : int\n",
    "            Number of channels in the first layer\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cifar_size: Final[int] = 32\n",
    "        self.n_chans1: Final[int] = n_chans1\n",
    "        self.cov_ker_size: Final[int] = 3\n",
    "        self.cov_pad: Final[int] = 1\n",
    "        # First convolutional layer (B, 3, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            n_chans1,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Second convolutional layer, after applying pooling (B, n_chans1, 16, 16)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            n_chans1,\n",
    "            n_chans1 // 2,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Third convolutional layer, after applying pooling (B, n_chans1, 8, 8)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            n_chans1 // 2,\n",
    "            n_chans1 // 2,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Functional layer after convolutions and view/reshape (B, n_chans1 * 8 * 8, 32)\n",
    "        self.fcn4 = nn.Linear(\n",
    "            ((self.cifar_size // 4) ** 2) * (n_chans1 // 2),\n",
    "            32\n",
    "        )\n",
    "        # Functional layer after functional (B, 2)\n",
    "        self.fcn5 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Propagate the batch forward through NN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : torch.Tensor\n",
    "            Batch of images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Forward propagated tensor\n",
    "        \"\"\"\n",
    "        out = nnf.max_pool2d(torch.tanh(self.conv1(batch)), 2)\n",
    "        out = nnf.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, self.fcn4.in_features)\n",
    "        out = torch.tanh(self.fcn4(out))\n",
    "        out = self.fcn5(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Cifar2CNN().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Linear(8 * 8 * 32 // 2, 32)\n",
    "l.out_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "c.out_channels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 32, 32])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_train[0][0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1024])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_train[0][0].view(-1, 8 * 8 * 16).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
