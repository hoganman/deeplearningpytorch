{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Networks (CNN)\n",
    "\n",
    "Convolutional neural networks (CNN) are powerful tools to perform image classification and segmentation. In this notebook, we explore the task of image classification using the CIFAR10 dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Final, Literal, Iterator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as nnf\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the data. The image normalization is taken from the web."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"../cifar_data\")\n",
    "\n",
    "class_names: list[str] = [\n",
    "    'airplane','automobile','bird','cat','deer',\n",
    "    'dog','frog','horse','ship','truck'\n",
    "]\n",
    "\n",
    "# Transform statistics taken from https://stackoverflow.com/a/69750247\n",
    "cifar10_preprocessor = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=cifar10_preprocessor\n",
    ")\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=cifar10_preprocessor\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since I got the normalization values from the Internet, I should verify that these statistics are accurate. I will create numpy batch arrays and take the mean and std along the batch and 32x32 pixel axes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# use np.concatenate to stick all the images together to form a (batch, 3, 32, 32) array\n",
    "imgs = np.concatenate(\n",
    "    np.asarray([[\n",
    "        [\n",
    "            cifar10_train[i][0][0].numpy(),\n",
    "            cifar10_train[i][0][1].numpy(),\n",
    "            cifar10_train[i][0][2].numpy()\n",
    "        ]\n",
    "        for i in range(len(cifar10_train))\n",
    "    ]])\n",
    ")\n",
    "\n",
    "print(imgs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The array has the correct shape (batch, channels, height, width).\n",
    "\n",
    "Since the image data was normalized, we should see zero mean and standard deviation of one (1) for the three channels."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00040607 -0.0005815  -0.00102856]\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean along the (batch, pixel, pixel) axes\n",
    "train_mean = np.mean(imgs, axis=(0, 2, 3))\n",
    "print(train_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0001289  0.9999368  0.99995327]\n"
     ]
    }
   ],
   "source": [
    "# calculate the std along the (batch, pixel, pixel) axes\n",
    "train_std = np.std(imgs, axis=(0, 2, 3))\n",
    "print(train_std)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! The data is normalized with zero mean and standard deviation of one (1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's use a simplified model of distinguishing birds from airplanes. Let's call this CIFAR2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# New class names\n",
    "cifar2_class_names: list[str] = ['airplane', 'bird']\n",
    "\n",
    "# Convert between CIFAR10 and CIFAR2\n",
    "cifar10_to_2_indices: list[int] = [\n",
    "    class_names.index(cifar2) for cifar2 in cifar2_class_names\n",
    "]\n",
    "label_map: dict[int, int] = { #{0: 0, 2: 1}\n",
    "    cifar2_ind: cifar10_ind\n",
    "    for (cifar10_ind, cifar2_ind) in enumerate(cifar10_to_2_indices)\n",
    "}\n",
    "\n",
    "cifar2 = [\n",
    "    (img, label_map[label])\n",
    "    for img, label in cifar10_train\n",
    "    if label in cifar10_to_2_indices\n",
    "]\n",
    "\n",
    "cifar2_val = [\n",
    "    (img, label_map[label])\n",
    "    for img, label in cifar10_val\n",
    "    if label in cifar10_to_2_indices\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One of important method to avoid overtraining is the use mini-batches selected in the training. Using the PyTorch DataLoader class provides this great functionality."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Depending on your host, you can use nVidia GPU granted it has CUDA support and installed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device: Final = (\n",
    "    torch.device('cuda') if torch.cuda.is_available()\n",
    "    else torch.device('cpu')\n",
    ")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's implement the training loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    \"\"\"Run training on a CNN\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_epochs : int\n",
    "        Number of training iterations\n",
    "    optimizer : optim.Optimizer\n",
    "        Optimizer\n",
    "    model : nn.Module\n",
    "        CNN model\n",
    "    loss_fn : nn.Module\n",
    "        Loss function module\n",
    "    train_loader : DataLoader\n",
    "        Batched data loader\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs_t, labels_t in train_loader:\n",
    "            imgs_t = imgs_t.to(device=device)\n",
    "            labels_t = labels_t.to(device=device)\n",
    "            outputs = model(imgs_t)\n",
    "            loss = loss_fn(outputs, labels_t)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch < 4 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now define the validation function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    \"\"\"Validate model training\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        Trained model module\n",
    "    train_loader : DataLoader\n",
    "        Training data loading\n",
    "    val_loader : DataLoader\n",
    "        Validation data loader\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, float]\n",
    "        Accuracy dictionary for data loaders. The keys are [\"train\", \"val\"]\n",
    "    \"\"\"\n",
    "    accdict: dict[Literal[\"train\", \"val\"], float] = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs_t, labels_t in loader:\n",
    "                outputs = model(imgs_t)\n",
    "                _, predicted_t = torch.max(outputs, dim=1)\n",
    "                total += labels_t.shape[0]\n",
    "                correct_t = predicted_t == labels_t\n",
    "                correct += int(correct_t.sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's define a small CNN that has 3 convolutional layers and two subsequent linear layers.\n",
    "\n",
    "While rectified linear unit activation function is the practitioner favorite, let's continue using tanh and compare the results.\n",
    "\n",
    "Let me include this important \"gotcha\" from the book. Consider some CNN model like below with the last layer with a log-softmax activation function and negative log-likelihood loss function.\n",
    "\n",
    "```python\n",
    "model = nn.Sequential(\n",
    "            ...,\n",
    "            nn.LogSoftmax(dim=1))\n",
    "optimizer = nn.NLLLoss()\n",
    "```\n",
    "\n",
    "\"_The combination of nn.LogSoftmax and nn.NLLLoss is equivalent to using nn.CrossEntropyLoss. This terminology is a particularity of PyTorch, as the nn.NLLoss computes, in fact, the cross entropy but with log probability predictions as inputs where nn.CrossEntropyLoss takes scores (sometimes called logits). Technically, nn.NLLLoss is the cross entropy between the Dirac distribution, putting all mass on the target, and the predicted distribution given by the log probability inputs._\n",
    "\n",
    "_To add to the confusion, in information theory, up to normalization by sample size, this cross entropy can be interpreted as a negative log likelihood of the predicted distribution under the target distribution as an outcome. So both losses are the negative log likelihood of the model parameters given the data when our model predicts the (softmax-applied) probabilities. In this book, we won’t rely on these details, but don’t let the PyTorch naming confuse you when you see the terms used in the literature._\n",
    "\n",
    "_It is quite common to drop the last nn.LogSoftmax layer from the network and use nn.CrossEntropyLoss as a loss._\"\n",
    "\n",
    "So let's keep this in mind for our application."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "class Cifar2CNN(nn.Module):\n",
    "    \"\"\"CNN image classifier for two (2) classes\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_chans1=32\n",
    "    ):\n",
    "        \"\"\"Instantiate a CNN CIFAR image classifier for two (2) classes.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_chans1 : int\n",
    "            Number of channels in the first layer\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cifar_size: Final[int] = 32\n",
    "        self.n_chans1: Final[int] = n_chans1\n",
    "        self.cov_ker_size: Final[int] = 3\n",
    "        self.cov_pad: Final[int] = 1\n",
    "        # First convolutional layer (B, 3, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            n_chans1,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Second convolutional layer, after applying pooling (B, n_chans1, 16, 16)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            n_chans1,\n",
    "            n_chans1 // 2,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Third convolutional layer, after applying pooling (B, n_chans1, 8, 8)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            n_chans1 // 2,\n",
    "            n_chans1 // 2,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Functional layer after convolutions and view/reshape (B, n_chans1 * 8 * 8, 32)\n",
    "        self.fcn4 = nn.Linear(\n",
    "            ((self.cifar_size // 4) ** 2) * (n_chans1 // 2),\n",
    "            32\n",
    "        )\n",
    "        # Output functional layer after functional (B, 2)\n",
    "        self.fcn5 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Propagate the batch forward through NN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : torch.Tensor\n",
    "            Batch of images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Forward propagated tensor\n",
    "        \"\"\"\n",
    "        out = nnf.max_pool2d(torch.tanh(self.conv1(batch)), 2)\n",
    "        out = nnf.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, self.fcn4.in_features)\n",
    "        out = torch.tanh(self.fcn4(out))\n",
    "        out = self.fcn5(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's try to train the model with a few epochs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-24 11:00:24.718264 Epoch 1, Training loss 0.5437281327262805\n",
      "2022-12-24 11:00:37.348607 Epoch 2, Training loss 0.45769688221299726\n",
      "2022-12-24 11:00:53.493002 Epoch 3, Training loss 0.411329961126777\n",
      "Accuracy train: 0.82\n",
      "Accuracy val: 0.83\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.8246, 'val': 0.8285}"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cifar2CNN().to(device=device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Neat! Now we have a classifier.\n",
    "\n",
    "Let's now demonstrate how we can use regularization to prevent overtraining. Using mini-batches already helps us, but this helps put us over-the-top. We could also explore other topics like Dropout."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "def reg_lq(param, q_val):\n",
    "    \"\"\"Regularization additive value for loss/objective function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param : Iterator[Parameter]\n",
    "        Iterator for model parameter tensors\n",
    "    q_val : float\n",
    "        Hyper-parameter value of the regularization power\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Single item tensor for regularization term\n",
    "    \"\"\"\n",
    "    return sum(p.pow(q_val).sum() for p in param)\n",
    "\n",
    "\n",
    "def reg_l2(param):\n",
    "    \"\"\"L2 ridge regularization term for a loss function\"\"\"\n",
    "    return reg_lq(param, 2.0)\n",
    "\n",
    "\n",
    "def reg_l1(param):\n",
    "    \"\"\"L2 euclidean regularization term for a loss function\"\"\"\n",
    "    return reg_lq(param, 1.0)\n",
    "\n",
    "\n",
    "def reg_elastic_net(param, scale):\n",
    "    \"\"\"Use elastic-net regularization as defined by 'Statistical Learning\n",
    "    with Sparsity' by Hastie et al. where the hyperparameter scale is\n",
    "    bounded [0, 1]\"\"\"\n",
    "    assert 0 <= scale <= 1\n",
    "    return 0.5 * (1.0 - scale) * reg_l2(param) + scale * reg_l1(param)\n",
    "\n",
    "\n",
    "def training_loop_reg(\n",
    "    n_epochs,\n",
    "    optimizer,\n",
    "    model,\n",
    "    loss_fn,\n",
    "    reg_fn,\n",
    "    reg_scale,\n",
    "    train_loader):\n",
    "    \"\"\"Run training on a CNN including regularization function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_epochs : int\n",
    "        Number of training iterations\n",
    "    optimizer : optim.Optimizer\n",
    "        Optimizer\n",
    "    model : nn.Module\n",
    "        CNN model\n",
    "    loss_fn : nn.Module\n",
    "        Loss function module\n",
    "    reg_fn : Callable\n",
    "        Regularization function\n",
    "    reg_scale : float\n",
    "        Regularization scale\n",
    "    train_loader : DataLoader\n",
    "        Batched data loader\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs_t, labels_t in train_loader:\n",
    "            imgs_t = imgs_t.to(device=device)\n",
    "            labels_t = labels_t.to(device=device)\n",
    "            outputs = model(imgs_t)\n",
    "            loss = loss_fn(outputs, labels_t)\n",
    "            reg = reg_fn(model.parameters())\n",
    "            loss += reg_scale * reg\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch <= 5 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-24 12:42:39.395332 Epoch 1, Training loss 0.5681598976159551\n",
      "2022-12-24 12:42:52.988805 Epoch 2, Training loss 0.4817252810213976\n",
      "2022-12-24 12:43:05.774594 Epoch 3, Training loss 0.4442047304028918\n",
      "2022-12-24 12:43:17.970108 Epoch 4, Training loss 0.40722736944058896\n",
      "2022-12-24 12:43:29.057511 Epoch 5, Training loss 0.38068383248748294\n",
      "Accuracy train: 0.83\n",
      "Accuracy val: 0.84\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.8343, 'val': 0.838}"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l2 = Cifar2CNN().to(device=device)\n",
    "optimizer_l2 = optim.SGD(model_l2.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop_reg(\n",
    "    n_epochs = 5,\n",
    "    optimizer = optimizer_l2,\n",
    "    model = model_l2,\n",
    "    loss_fn = nn.CrossEntropyLoss(),\n",
    "    reg_fn = reg_l2,\n",
    "    reg_scale = 1e-5,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model_l2, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-24 12:50:57.417654 Epoch 1, Training loss 0.5543369795106778\n",
      "2022-12-24 12:51:08.549444 Epoch 2, Training loss 0.4782435994619017\n",
      "2022-12-24 12:51:20.202710 Epoch 3, Training loss 0.4442253862596621\n",
      "2022-12-24 12:51:31.117058 Epoch 4, Training loss 0.40231277209937955\n",
      "2022-12-24 12:51:46.275318 Epoch 5, Training loss 0.3692555131426283\n",
      "Accuracy train: 0.84\n",
      "Accuracy val: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.8413, 'val': 0.846}"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_l1 = Cifar2CNN().to(device=device)\n",
    "optimizer_l1 = optim.SGD(model_l1.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop_reg(\n",
    "    n_epochs = 5,\n",
    "    optimizer = optimizer_l1,\n",
    "    model = model_l1,\n",
    "    loss_fn = nn.CrossEntropyLoss(),\n",
    "    reg_fn = reg_l1,\n",
    "    reg_scale = 1e-5,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model_l1, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-24 12:52:13.437420 Epoch 1, Training loss 0.5380308445851514\n",
      "2022-12-24 12:52:24.351737 Epoch 2, Training loss 0.46329990731682746\n",
      "2022-12-24 12:52:36.200076 Epoch 3, Training loss 0.4245817234182054\n",
      "2022-12-24 12:52:48.165033 Epoch 4, Training loss 0.3874200144960622\n",
      "2022-12-24 12:52:59.909681 Epoch 5, Training loss 0.3606618495693632\n",
      "Accuracy train: 0.85\n",
      "Accuracy val: 0.85\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'train': 0.8462, 'val': 0.8475}"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_elnet = Cifar2CNN().to(device=device)\n",
    "optimizer_elnet = optim.SGD(model_elnet.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop_reg(\n",
    "    n_epochs = 5,\n",
    "    optimizer = optimizer_elnet,\n",
    "    model = model_elnet,\n",
    "    loss_fn = nn.CrossEntropyLoss(),\n",
    "    reg_fn = lambda p: reg_elastic_net(p, 0.5),\n",
    "    reg_scale = 1e-5,\n",
    "    train_loader = train_loader,\n",
    ")\n",
    "\n",
    "validate(model_elnet, train_loader, val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we had a more challenging problem than using binary classification like person recognition would be more interesting."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
