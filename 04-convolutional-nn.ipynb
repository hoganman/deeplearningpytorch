{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Final\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as nnf\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"../cifar_data\")\n",
    "\n",
    "class_names: list[str] = [\n",
    "    'airplane','automobile','bird','cat','deer',\n",
    "    'dog','frog','horse','ship','truck'\n",
    "]\n",
    "\n",
    "# Transform statistics taken from https://stackoverflow.com/a/69750247\n",
    "cifar10_preprocessor = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=cifar10_preprocessor\n",
    ")\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=cifar10_preprocessor\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since I got the normalization values from the Internet, I should verify that these statistics are accurate. I will create numpy batch arrays and take the mean and std along the batch and 32x32 pixel axes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# use np.concatenate to stick all the images together to form a (batch, 3, 32, 32) array\n",
    "imgs = np.concatenate(\n",
    "    np.asarray([[\n",
    "        [\n",
    "            cifar10_train[i][0][0].numpy(),\n",
    "            cifar10_train[i][0][1].numpy(),\n",
    "            cifar10_train[i][0][2].numpy()\n",
    "        ]\n",
    "        for i in range(len(cifar10_train))\n",
    "    ]])\n",
    ")\n",
    "\n",
    "print(imgs.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00040607 -0.0005815  -0.00102856]\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean along the (batch, pixel, pixel) axes\n",
    "train_mean = np.mean(imgs, axis=(0, 2, 3))\n",
    "print(train_mean)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0001289  0.9999368  0.99995327]\n"
     ]
    }
   ],
   "source": [
    "# calculate the std along the (batch, pixel, pixel) axes\n",
    "train_std = np.std(imgs, axis=(0, 2, 3))\n",
    "print(train_std)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Great! The data is normalized with zero mean and standard deviation of one (1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "label_map: dict[int, int] = {0: 0, 2: 1}\n",
    "\n",
    "cifar2_class_names: list[str] = ['airplane', 'bird']\n",
    "cifar10_to_2_indices: list[int] = [\n",
    "    class_names.index(cifar2) for cifar2 in cifar2_class_names\n",
    "]\n",
    "\n",
    "cifar2 = [\n",
    "    (img, label_map[label])\n",
    "    for img, label in cifar10_train\n",
    "    if label in cifar10_to_2_indices\n",
    "]\n",
    "\n",
    "cifar2_val = [\n",
    "    (img, label_map[label])\n",
    "    for img, label in cifar10_val\n",
    "    if label in cifar10_to_2_indices\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar2, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar2_val, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Cifar2CNN(nn.Module):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_chans1=32\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_chans1 : int\n",
    "            Number of channels in the first layer\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cifar_size: Final[int] = 32\n",
    "        self.n_chans1: Final[int] = n_chans1\n",
    "        self.cov_ker_size: Final[int] = 3\n",
    "        self.cov_pad: Final[int] = 1\n",
    "        # First convolutional layer (B, 3, 32, 32)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3,\n",
    "            n_chans1,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Second convolutional layer, after applying pooling (B, n_chans1, 16, 16)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            n_chans1,\n",
    "            n_chans1 // 2,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Third convolutional layer, after applying pooling (B, n_chans1, 8, 8)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            n_chans1 // 2,\n",
    "            n_chans1 // 2,\n",
    "            self.cov_ker_size,\n",
    "            padding=self.cov_pad\n",
    "        )\n",
    "        # Functional layer after convolutions and view/reshape (B, n_chans1 * 8 * 8, 32)\n",
    "        self.fcn4 = nn.Linear(\n",
    "            ((self.cifar_shape // 4) ** 2) * (n_chans1 // 2),\n",
    "            32\n",
    "        )\n",
    "        # Functional layer after functional (B, 2)\n",
    "        self.fcn5 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        \"\"\"Propagate the batch forward through NN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch : torch.Tensor\n",
    "            Batch of images\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Forward propagated tensor\n",
    "        \"\"\"\n",
    "        out = nnf.max_pool2d(torch.tanh(self.conv1(batch)), 2)\n",
    "        out = nnf.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, self.fcn4.in_features)\n",
    "        out = torch.tanh(self.fcn4(out))\n",
    "        out = self.fcn5(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.Linear(8 * 8 * 32 // 2, 32)\n",
    "l.out_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "32"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "c.out_channels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 32, 32])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_train[0][0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1024])"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar10_train[0][0].view(-1, 8 * 8 * 16).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
